{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow and Keras 101 <a class=\"tocSkip\">\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/armando-fandango/<-path-to-repo>\"><img src=\"https://colab.research.google.com/img/colab_favicon.ico\" style=\"width:30px;\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/armando-fandango/<-path-to-repo>\"><img src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Logo.png\" style=\"width:70px;\" vspace=\"7px\"/>View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Install-TensorFlow-2.0-alpha\" data-toc-modified-id=\"Install-TensorFlow-2.0-alpha-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Install TensorFlow 2.0 alpha</a></span></li><li><span><a href=\"#Import-TensorFlow-and-Keras\" data-toc-modified-id=\"Import-TensorFlow-and-Keras-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import TensorFlow and Keras</a></span></li><li><span><a href=\"#Customary-Hello-TensorFlow-!!!\" data-toc-modified-id=\"Customary-Hello-TensorFlow-!!!-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Customary Hello TensorFlow !!!</a></span></li><li><span><a href=\"#Constants\" data-toc-modified-id=\"Constants-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Constants</a></span></li><li><span><a href=\"#Variables\" data-toc-modified-id=\"Variables-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Variables</a></span></li><li><span><a href=\"#Operations\" data-toc-modified-id=\"Operations-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Operations</a></span></li><li><span><a href=\"#Creating-Tensors-from-Existing-Objects\" data-toc-modified-id=\"Creating-Tensors-from-Existing-Objects-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Creating Tensors from Existing Objects</a></span><ul class=\"toc-item\"><li><span><a href=\"#0-Dimensional-Tensors-(Scalars)\" data-toc-modified-id=\"0-Dimensional-Tensors-(Scalars)-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>0-Dimensional Tensors (Scalars)</a></span></li><li><span><a href=\"#1-Dimensional-Tensors-(Vectors)\" data-toc-modified-id=\"1-Dimensional-Tensors-(Vectors)-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>1-Dimensional Tensors (Vectors)</a></span></li><li><span><a href=\"#2-Dimensional-Tensors-(Matrices)\" data-toc-modified-id=\"2-Dimensional-Tensors-(Matrices)-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>2-Dimensional Tensors (Matrices)</a></span></li><li><span><a href=\"#3-Dimensional-Tensors\" data-toc-modified-id=\"3-Dimensional-Tensors-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>3-Dimensional Tensors</a></span></li></ul></li><li><span><a href=\"#Creating-Tensors-from-Library-Functions\" data-toc-modified-id=\"Creating-Tensors-from-Library-Functions-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Creating Tensors from Library Functions</a></span></li><li><span><a href=\"#Training-model-using-Keras-Sequential-API\" data-toc-modified-id=\"Training-model-using-Keras-Sequential-API-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Training model using Keras Sequential API</a></span></li><li><span><a href=\"#Advanced\" data-toc-modified-id=\"Advanced-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Advanced</a></span></li><li><span><a href=\"#TensorBoard\" data-toc-modified-id=\"TensorBoard-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>TensorBoard</a></span><ul class=\"toc-item\"><li><span><a href=\"#Use-Jupyter-TensorBoard-plugin\" data-toc-modified-id=\"Use-Jupyter-TensorBoard-plugin-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>Use Jupyter TensorBoard plugin</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports to make notebook compatible with Python 2\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install TensorFlow 2.0 alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==2.0.0-alpha0\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting google-pasta>=0.1.2 (from tensorflow-gpu==2.0.0-alpha0)\n",
      "  Using cached https://files.pythonhosted.org/packages/64/bb/f1bbc131d6294baa6085a222d29abadd012696b73dcbf8cf1bf56b9f082a/google_pasta-0.1.5-py3-none-any.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-gpu==2.0.0-alpha0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/anaconda3/envs/tf2/lib/python3.6/site-packages (from tensorflow-gpu==2.0.0-alpha0) (1.12.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/anaconda3/envs/tf2/lib/python3.6/site-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.1)\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow-gpu==2.0.0-alpha0)\n",
      "  Using cached https://files.pythonhosted.org/packages/90/85/64c82949765cfb246bbdaf5aca2d55f400f792655927a017710a78445def/Keras_Applications-1.0.7-py2.py3-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow-gpu==2.0.0-alpha0)\n",
      "Collecting protobuf>=3.6.1 (from tensorflow-gpu==2.0.0-alpha0)\n",
      "  Using cached https://files.pythonhosted.org/packages/5a/aa/a858df367b464f5e9452e1c538aa47754d467023850c00b000287750fa77/protobuf-3.7.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /opt/anaconda3/envs/tf2/lib/python3.6/site-packages (from tensorflow-gpu==2.0.0-alpha0) (1.16.2)\n",
      "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow-gpu==2.0.0-alpha0)\n",
      "  Using cached https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl\n",
      "Collecting astor>=0.6.0 (from tensorflow-gpu==2.0.0-alpha0)\n",
      "  Using cached https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow-gpu==2.0.0-alpha0)\n",
      "  Using cached https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow-gpu==2.0.0-alpha0)\n",
      "  Using cached https://files.pythonhosted.org/packages/f4/dc/5503d89e530988eb7a1aed337dcb456ef8150f7c06132233bd9e41ec0215/grpcio-1.19.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting absl-py>=0.7.0 (from tensorflow-gpu==2.0.0-alpha0)\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow-gpu==2.0.0-alpha0)\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/bf/0315ef6a9fd3fc2346e85b0ff1f5f83ca17073f2c31ac719ab2e4da0d4a3/Keras_Preprocessing-1.0.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/envs/tf2/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/tf2/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (40.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/anaconda3/envs/tf2/lib/python3.6/site-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.14.1)\n",
      "Collecting markdown>=2.6.8 (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0)\n",
      "  Using cached https://files.pythonhosted.org/packages/f5/e4/d8c18f2555add57ff21bf25af36d827145896a07607486cc79a2aea641af/Markdown-3.1-py2.py3-none-any.whl\n",
      "Installing collected packages: google-pasta, termcolor, keras-applications, gast, protobuf, grpcio, markdown, absl-py, tb-nightly, astor, tf-estimator-nightly, keras-preprocessing, tensorflow-gpu\n",
      "Successfully installed absl-py-0.7.1 astor-0.7.1 gast-0.2.2 google-pasta-0.1.5 grpcio-1.19.0 keras-applications-1.0.7 keras-preprocessing-1.0.9 markdown-3.1 protobuf-3.7.1 tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 termcolor-1.1.0 tf-estimator-nightly-1.14.0.dev2019030115\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu==2.0.0-alpha0\n",
    "\n",
    "# Uncomment the command below if you would rather experiment with nightly version\n",
    "!pip install tf-nightly-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import TensorFlow and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python : 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) \n",
      "[GCC 7.3.0]\n",
      "tensorflow : 2.0.0-dev20190421\n",
      "tensorflow.keras : 2.2.4-tf\n",
      "numpy : 1.16.2\n",
      "pandas : 0.24.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "print('Python : {}'.format(sys.version))\n",
    "for module in tf, keras, np, pd:\n",
    "    print('{} : {}'.format(module.__name__, module.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customary Hello TensorFlow !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello TensorFlow 2 !!\n"
     ]
    }
   ],
   "source": [
    "hello = tf.constant('Hello TensorFlow 2 !!')\n",
    "tf.print(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Hello TensorFlow 2 !!', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(hello)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 (x):  tf.Tensor(5, shape=(), dtype=int32)\n",
      "c2 (y):  tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "c3 (z):  tf.Tensor(7.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c1 = tf.constant(5, name='x')\n",
    "c2 = tf.constant(6.0, name='y')\n",
    "c3 = tf.constant(7.0, dtype=tf.float32, name='z')\n",
    "print('c1 (x): ', c1)\n",
    "print('c2 (y): ', c2)\n",
    "print('c3 (z): ', c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "tf.print([c1, c2, c3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w:0' shape=(1,) dtype=float32, numpy=array([0.3], dtype=float32)>\n",
      "[0.3]\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable([.3], dtype=tf.float32,name='w')\n",
    "print(w)\n",
    "tf.print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: <tf.Variable 'w:0' shape=(1,) dtype=float32, numpy=array([0.3], dtype=float32)>\n",
      "b: <tf.Variable 'b:0' shape=(1,) dtype=float32, numpy=array([-0.3], dtype=float32)>\n",
      "x: [1, 2, 3, 4]\n",
      "y: tf.Tensor([0.         0.3        0.6        0.90000004], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Linear Model y = w * x + b\n",
    "\n",
    "# Define model parameters\n",
    "w = tf.Variable([.3], dtype=tf.float32,name='w')\n",
    "b = tf.Variable([-.3], dtype=tf.float32,name='b')\n",
    "\n",
    "# define model with inputs as arguments\n",
    "@tf.function\n",
    "def linear(x):\n",
    "    return w * x + b\n",
    "\n",
    "# define input array\n",
    "x = [1,2,3,4]\n",
    "\n",
    "# get output from the model by passing input\n",
    "y=linear(x)\n",
    "\n",
    "print(\"w:\", w)\n",
    "print(\"b:\", b)\n",
    "print(\"x:\", x)\n",
    "print(\"y:\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op1 :  tf.Tensor(13.0, shape=(), dtype=float32)\n",
      "op2 :  tf.Tensor(42.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "op1 = tf.add(c2, c3)\n",
    "op2 = tf.multiply(c2, c3)\n",
    "print('op1 : ', op1)\n",
    "print('op2 : ', op2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op1 :  13\n",
      "op2 :  42\n"
     ]
    }
   ],
   "source": [
    "tf.print('op1 : ', op1)\n",
    "tf.print('op2 : ', op2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Tensors from Existing Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-Dimensional Tensors (Scalars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_t :  tf.Tensor(5.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "tf_t = tf.convert_to_tensor(5.0, dtype=tf.float64)\n",
    "\n",
    "print('tf_t : ', tf_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Dimensional Tensors (Vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1dim Shape :  (5,)\n",
      "tf_t :  tf.Tensor([1.   2.   3.   4.   5.99], shape=(5,), dtype=float64)\n",
      "tf_t[0] :  1\n",
      "tf_t[2] :  3\n"
     ]
    }
   ],
   "source": [
    "a1dim = np.array([1, 2, 3, 4, 5.99])\n",
    "print(\"a1dim Shape : \", a1dim.shape)\n",
    "\n",
    "tf_t = tf.convert_to_tensor(a1dim, dtype=tf.float64)\n",
    "\n",
    "print('tf_t : ', tf_t)\n",
    "tf.print('tf_t[0] : ', tf_t[0])\n",
    "tf.print('tf_t[2] : ', tf_t[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Dimensional Tensors (Matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2dim Shape :  (3, 5)\n",
      "tf_t :  tf.Tensor(\n",
      "[[1.   2.   3.   4.   5.99]\n",
      " [2.   3.   4.   5.   6.99]\n",
      " [3.   4.   5.   6.   7.99]], shape=(3, 5), dtype=float64)\n",
      "tf_t[0][0] :  1\n",
      "tf_t[1][2] :  4\n"
     ]
    }
   ],
   "source": [
    "a2dim = np.array([(1, 2, 3, 4, 5.99),\n",
    "                  (2, 3, 4, 5, 6.99),\n",
    "                  (3, 4, 5, 6, 7.99)\n",
    "                  ])\n",
    "print(\"a2dim Shape : \", a2dim.shape)\n",
    "\n",
    "tf_t = tf.convert_to_tensor(a2dim, dtype=tf.float64)\n",
    "\n",
    "print('tf_t : ', tf_t)\n",
    "tf.print('tf_t[0][0] : ', tf_t[0][0])\n",
    "tf.print('tf_t[1][2] : ', tf_t[1][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Dimensional Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3dim Shape :  (2, 2, 2)\n",
      "tf_t :  tf.Tensor(\n",
      "[[[1. 2.]\n",
      "  [3. 4.]]\n",
      "\n",
      " [[5. 6.]\n",
      "  [7. 8.]]], shape=(2, 2, 2), dtype=float64)\n",
      "tf_t[0][0][0] :  1\n",
      "tf_t[1][1][1] :  8\n"
     ]
    }
   ],
   "source": [
    "a3dim = np.array([[[1, 2],\n",
    "                   [3, 4]\n",
    "                   ],\n",
    "                  [[5, 6],\n",
    "                   [7, 8]\n",
    "                   ]\n",
    "                  ])\n",
    "print(\"a3dim Shape : \", a3dim.shape)\n",
    "\n",
    "tf_t = tf.convert_to_tensor(a3dim, dtype=tf.float64)\n",
    "\n",
    "print('tf_t : ', tf_t)\n",
    "tf.print('tf_t[0][0][0] : ', tf_t[0][0][0])\n",
    "tf.print('tf_t[1][1][1] : ', tf_t[1][1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Tensors from Library Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]], shape=(5, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]], shape=(5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.zeros((5,4))\n",
    "print(a)\n",
    "a = tf.ones((5,4))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model using Keras Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2983 - accuracy: 0.9123\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.1460 - accuracy: 0.9565\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1104 - accuracy: 0.9665\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0902 - accuracy: 0.9720\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0782 - accuracy: 0.9754\n",
      "10000/10000 [==============================] - 0s 42us/sample - loss: 0.0736 - accuracy: 0.9775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07355862732266541, 0.9775]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/b8/457ad44e8748fbe5021b4ca7e7d589b5852881bbb11bca4d947952a13558/tensorflow_datasets-1.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/anaconda3/envs/tf2/lib/python3.6/site-packages (from tensorflow_datasets) (3.7.1)\n",
      "Collecting promise (from tensorflow_datasets)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/tf2/lib/python3.6/site-packages (from tensorflow_datasets) (2.21.0)\n",
      "Collecting tensorflow-metadata (from tensorflow_datasets)\n",
      "  Using cached https://files.pythonhosted.org/packages/08/b7/3fc74574aa9aff44491cce996711dd6094653c20d9e2800be4efb054e0da/tensorflow_metadata-0.13.0-py3-none-any.whl\n",
      "Requirement already satisfied: termcolor in /opt/anaconda3/envs/tf2/lib/python3.6/site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Collecting tqdm (from tensorflow_datasets)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 3.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting future (from tensorflow_datasets)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/52/e20466b85000a181e1e144fd8305caf2cf475e2f9674e797b222f8105f5f/future-0.17.1.tar.gz (829kB)\n",
      "\u001b[K    100% |████████████████████████████████| 829kB 14.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/anaconda3/envs/tf2/lib/python3.6/site-packages (from tensorflow_datasets) (1.12.0)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/envs/tf2/lib/python3.6/site-packages (from tensorflow_datasets) (1.11.1)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/envs/tf2/lib/python3.6/site-packages (from tensorflow_datasets) (0.7.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/tf2/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow_datasets) (40.8.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/anaconda3/envs/tf2/lib/python3.6/site-packages (from requests->tensorflow_datasets) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda3/envs/tf2/lib/python3.6/site-packages (from requests->tensorflow_datasets) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/envs/tf2/lib/python3.6/site-packages (from requests->tensorflow_datasets) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/tf2/lib/python3.6/site-packages (from requests->tensorflow_datasets) (2019.3.9)\n",
      "Collecting googleapis-common-protos (from tensorflow-metadata->tensorflow_datasets)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/armando/.cache/pip/wheels/0c/61/d2/d6b7317325828fbb39ee6ad559dbe4664d0896da4721bf379e\n",
      "Successfully built future\n",
      "Installing collected packages: promise, googleapis-common-protos, tensorflow-metadata, tqdm, future, tensorflow-datasets\n",
      "Successfully installed future-0.17.1 googleapis-common-protos-1.5.9 promise-2.2.1 tensorflow-datasets-1.0.1 tensorflow-metadata-0.13.0 tqdm-4.31.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.13769465684890747, Accuracy: 95.88166809082031, Test Loss: 0.05883735418319702, Test Accuracy: 98.1500015258789\n",
      "Epoch 2, Loss: 0.09008178114891052, Accuracy: 97.28916931152344, Test Loss: 0.05430900305509567, Test Accuracy: 98.25\n",
      "Epoch 3, Loss: 0.06765960901975632, Accuracy: 97.9383316040039, Test Loss: 0.05177422612905502, Test Accuracy: 98.33999633789062\n",
      "Epoch 4, Loss: 0.05370677262544632, Accuracy: 98.35291290283203, Test Loss: 0.053110141307115555, Test Accuracy: 98.34750366210938\n",
      "Epoch 5, Loss: 0.04471990838646889, Accuracy: 98.62566375732422, Test Loss: 0.05705774202942848, Test Accuracy: 98.29800415039062\n"
     ]
    }
   ],
   "source": [
    "dataset, info = tfds.load('mnist', data_dir='gs://tfds-data/datasets', with_info=True, as_supervised=True)\n",
    "mnist_train, mnist_test = dataset['train'], dataset['test']\n",
    "\n",
    "def convert_types(image, label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image /= 255\n",
    "  return image, label\n",
    "\n",
    "mnist_train = mnist_train.map(convert_types).shuffle(10000).batch(32)\n",
    "mnist_test = mnist_test.map(convert_types).batch(32)\n",
    "\n",
    "class MyModel(Model):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "    self.flatten = Flatten()\n",
    "    self.d1 = Dense(128, activation='relu')\n",
    "    self.d2 = Dense(10, activation='softmax')\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.d1(x)\n",
    "    return self.d2(x)\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "loss_object = keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "train_loss = keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(image, label):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(image)\n",
    "    loss = loss_object(label, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(label, predictions)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(image, label):\n",
    "  predictions = model(image)\n",
    "  t_loss = loss_object(label, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(label, predictions)\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  for image, label in mnist_train:\n",
    "    train_step(image, label)\n",
    "\n",
    "  for test_image, test_label in mnist_test:\n",
    "    test_step(test_image, test_label)\n",
    "\n",
    "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "  print (template.format(epoch+1,\n",
    "                         train_loss.result(),\n",
    "                         train_accuracy.result()*100,\n",
    "                         test_loss.result(),\n",
    "                         test_accuracy.result()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load TensorBoard notebook extension\n",
    "%load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa6f3fdee48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, datetime\n",
    "\n",
    "logs_dir = \"./tflogs\"\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "#logs_dir = os.path.join(logs_dir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "%tensorboard --logdir {logs_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: <tf.Variable 'w:0' shape=(1,) dtype=float32, numpy=array([0.3], dtype=float32)>\n",
      "b: <tf.Variable 'b:0' shape=(1,) dtype=float32, numpy=array([-0.3], dtype=float32)>\n",
      "x: [1, 2, 3, 4]\n",
      "y: tf.Tensor([0.         0.3        0.6        0.90000004], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable([.3], dtype=tf.float32,name='w')\n",
    "b = tf.Variable([-.3], dtype=tf.float32,name='b')\n",
    "    \n",
    "@tf.function\n",
    "def linear(x):\n",
    "    return w * x + b\n",
    "\n",
    "x = [1,2,3,4]\n",
    "\n",
    "y=linear(x)\n",
    "\n",
    "print(\"w:\", w)\n",
    "print(\"b:\", b)\n",
    "print(\"x:\", x)\n",
    "print(\"y:\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Jupyter TensorBoard plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install using the following commands:\n",
    "\n",
    "pip install jupyter-tensorboard --upgrade\n",
    "\n",
    "jupyter tensorboard enable --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "306px",
    "width": "240px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
